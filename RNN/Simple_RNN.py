# -*- coding: utf-8 -*-
"""Simple_RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uEwi6CX_PT3Ku0Lcbkl3JHPmgotj36Fw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, SimpleRNN

# Load the dataset
dataset = pd.read_csv('/content/oil.csv')

# Select the feature (e.g., 'Sales') and convert it to a numpy array
data = dataset['dcoilwtico']
data

# Reshape data and scale it
data = data.reshape(-1, 1)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create the training data set
training_data_len = int(np.round(len(scaled_data) * 0.8))
train_data = scaled_data[0:int(training_data_len), :]

# Split the data into x_train and y_train data sets
def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)
look_back = 60
X_train, y_train = create_dataset(train_data, look_back)

# Reshape input to be [samples, time steps, features]
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Build the RNN model
model = Sequential()
model.add(SimpleRNN(50, return_sequences=True, input_shape=(look_back, 1)))
model.add(SimpleRNN(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, batch_size=1, epochs=1)

# Create the testing data set
test_data = scaled_data[training_data_len - look_back:, :]
X_test, y_test = create_dataset(test_data, look_back)

# Reshape input to be [samples, time steps, features]
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Make predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)

# Evaluate the model
rmse = np.sqrt(np.mean((predictions - y_test) ** 2))
print('RMSE:', rmse)

# Visualize the results
train = dataset[:training_data_len]
valid = dataset[training_data_len:]
valid = valid.iloc[:len(predictions)]  # Adjust the length of the validation set to match predictions
valid['Predictions'] = predictions

plt.figure(figsize=(16, 8))
plt.title('Sales Forecasting')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.plot(train['dcoilwtico'])
plt.plot(valid[['dcoilwtico', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()